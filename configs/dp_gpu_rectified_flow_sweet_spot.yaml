seed: 0
device: cuda

# Sweet-spot setting where a small labeled target reference set benefits a lot
# from adding transported synthetic samples (acc_ref_plus_synth >> acc_ref_only).
data:
  type: federated_mixture_gaussians
  params:
    K: 6
    n_per_client: 1500
    n_target_ref: 2000
    n_target_test: 1000
    d: 30
    num_classes: 6
    component_scale: 5.0
    component_cov: 3.0
    seed: 0

loaders:
  batch_size: 256
  target_batch_size: 256
  test_batch_size: 512
  synth_batch_size: 512
  drop_last: true

stage1:
  epochs: 40
  lr: 0.001
  hidden: [128, 128]
  time_emb_dim: 32
  label_emb_dim: 32
  label_prior:
    enabled: true
    mechanism: gaussian
    sigma: 1.0
  dp:
    enabled: true
    max_grad_norm: 1.0
    noise_multiplier: 1.0
    delta: 1e-5
    grad_sample_mode: functorch

stage2:
  option: A
  # Avoid class-permutation / label-switch by pairing target points by label during OT training.
  pair_by_label: true
  epochs: 60
  lr: 0.001
  flow_steps: 50
  dp:
    enabled: true
    max_grad_norm: 1.0
    noise_multiplier: 1.0
    delta: 1e-5
    grad_sample_mode: functorch
  cellot:
    enabled: false
  rectified_flow:
    enabled: true
    hidden: [256, 256]
    time_emb_dim: 64
    act: silu
    transport_steps: 50

stage3:
  epochs: 30
  lr: 0.001
  hidden: [128, 128]
  flow_steps: 50
  # Reduce synthetic training set size (K * M_per_client total).
  M_per_client: 500
  # Use only a small labeled subset of target_ref for supervised baselines.
  ref_train_size: 50

privacy_curve:
  enabled: false
  stage: stage1
  noise_multipliers: [0.5, 1.0, 2.0, 4.0]
  output_path: privacy_utility.png

membership_inference:
  enabled: false
  max_samples: 2000
  seed: 0

shadow_mia:
  enabled: false
  num_shadow_models: 2
  shadow_train_size: 2000
  shadow_test_size: 2000
  shadow_epochs: 5
  shadow_lr: 0.001
  shadow_hidden: [128, 128]
  shadow_batch_size: 256
  attack_epochs: 20
  attack_lr: 0.001
  attack_hidden: [64, 32]
  attack_batch_size: 256
  feature_set: stats
  max_samples_per_shadow: 2000
  seed: 0
  data_overrides: {}

stage_mia:
  enabled: false
  holdout_fraction: 0.2
  num_flow_samples: 1
  include_ot_transport_norm: true
  attack_train_frac: 0.5
  attack_hidden: [64, 32]
  attack_epochs: 20
  attack_lr: 0.001
  attack_batch_size: 256
  max_samples: 2000
  seed: 0

stage_shadow_mia:
  enabled: false
  num_shadow_models: 2
  holdout_fraction: 0.2
  num_flow_samples: 1
  include_ot_transport_norm: true
  attack_train_frac: 0.5
  attack_hidden: [64, 32]
  attack_epochs: 20
  attack_lr: 0.001
  attack_batch_size: 256
  max_samples_per_shadow: 2000
  seed: 0
  data_overrides: {}
